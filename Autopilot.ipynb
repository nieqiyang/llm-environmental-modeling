{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Project: RRI Model Parameter Calibration via Browser-based Claude\n",
    "Description:\n",
    "    This script controls a browser-based Claude (via Selenium/Undetected-Chromedriver)\n",
    "    to perform automatic iterative optimization of RRI model parameters.\n",
    "    Note: The Claude interface may update, so selectors might need adjustment based on actual UI.\n",
    "    \n",
    "    Overall Workflow:\n",
    "    1.  Launch Chrome browser and navigate to Claude.ai.\n",
    "    2.  User manually logs into their Claude account.\n",
    "    3.  The script reads an initial prompt and sends it to Claude to obtain a set of initial parameters.\n",
    "    4.  The script then runs the RRI hydrological model (Fortran .exe) with these parameters to evaluate their performance.\n",
    "    5.  The evaluation results (specifically, NSE scores) are fed back to Claude to request a new, improved set of parameters for the next iteration.\n",
    "    6.  This process (sending parameters, running model, feeding back results) loops until the maximum number of optimization rounds is reached.\n",
    "\n",
    "Important Notes: \n",
    "    - You need to modify `CHROMEDRIVER_PATH` to your local chromedriver executable path.\n",
    "    - If the Claude interface language is not Japanese, you might need to adjust the `aria-label` values in CSS Selectors (e.g., from \"応答を停止\" to \"Stop generating\").\n",
    "\"\"\"\n",
    "\n",
    "import os        \n",
    "import re        \n",
    "import ast      \n",
    "import time      \n",
    "import random    \n",
    "import subprocess \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from osgeo import gdal \n",
    "\n",
    "# Selenium related imports for browser automation\n",
    "from selenium.webdriver.chrome.service import Service \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException \n",
    "import undetected_chromedriver as uc \n",
    "\n",
    "# ==========================================\n",
    "# 1. Global Configuration & Path Settings\n",
    "# ==========================================\n",
    "\n",
    "# 1.1 File Path Configuration\n",
    "PATHS = {\n",
    "    'dem': \"topo/dem_250.tif\",        # Path to the Digital Elevation Model (DEM) GeoTIFF file.\n",
    "    'out_folder': \"out\",              # Directory where the raw RRI model output files will be saved.\n",
    "    'result_folder': \"results\",       # Directory for processed results and intermediate files.\n",
    "    'out_prefix': \"qr\",               # Prefix for RRI model output files (e.g., qr_1.out, qr_2.out).\n",
    "    'rri_exe': \"0_rri_1_4_2_6.exe\",   # Path to the RRI hydrological model executable (compiled Fortran program).\n",
    "    'rri_input': \"RRI_Input.txt\",     # Path to the RRI model's input configuration file.\n",
    "    'obs_data': \"./results/obsQ.xlsx\",# Path to the Excel file containing observed discharge (flow) data.\n",
    "    'rain_folder': \"./rain\",          # Directory containing rainfall input data files for the RRI model.\n",
    "    'prompt_file': \"Prompt.txt\"       # Path to the text file storing the initial prompt for Claude.\n",
    "}\n",
    "\n",
    "# 1.2 Browser Driver Path \n",
    "CHROMEDRIVER_PATH = r\"./chromedriver.exe\" # User-specific path to the ChromeDriver executable.\n",
    "\n",
    "# 1.3 Optimization Settings\n",
    "MAX_ROUNDS = 30        # Maximum number of optimization/dialogue rounds with Claude.\n",
    "PAUSE_SECONDS = 5     # Cooldown time (in seconds) after each optimization round to avoid overwhelming Claude or rate limits.\n",
    "\n",
    "# 1.4 Observation Point Coordinates (Longitude, Latitude)\n",
    "LOCATIONS = [\n",
    "    (136.16375, 36.0081) # A list of (longitude, latitude) tuples for points where simulated data will be extracted.\n",
    "]\n",
    "\n",
    "# 1.5 Rainfall Event List (Filename, Simulation Duration in Hours)\n",
    "RAIN_EVENTS = [\n",
    "    ('rain_merged_precipitation_20040717_to_20040723.dat', 168), # Tuple: rain data filename and corresponding simulation duration.\n",
    "    ('rain_merged_precipitation_20041019_to_20041022.dat', 81),\n",
    "    ('rain_merged_precipitation_20050630_to_20050709.dat', 240),\n",
    "    ('rain_merged_precipitation_20110707_to_20110711.dat', 120),\n",
    "    ('rain_merged_precipitation_20110919_to_20110926.dat', 192),\n",
    "    ('rain_merged_precipitation_20171021_to_20171028.dat', 192),\n",
    "    ('rain_merged_precipitation_20180704_to_20180711.dat', 192)\n",
    "]\n",
    "\n",
    "# 1.6 Fixed Parameters and Initial Template\n",
    "FIXED_PARAMS = {\n",
    "    'ksv_1': 0.0000, 'ksv_2': 0.0000, # Parameters that remain constant during the optimization process.\n",
    "    'faif_1': 0.0000, 'faif_2': 0.0000\n",
    "}\n",
    "\n",
    "INITIAL_PARAMS = {\n",
    "    'ns_river': 0.05,                   # Initial values for the RRI model parameters that will be optimized.\n",
    "    'ns_slope_1': 0.4, 'soildepth_1': 1.0, 'gammaa_1': 0.4, 'gammam_1': 0.1, 'ka_1': 0.1, 'beta_1': 8.0,\n",
    "    'ns_slope_2': 0.4, 'soildepth_2': 1.0, 'gammaa_2': 0.4, 'gammam_2': 0.1, 'ka_2': 0.1, 'beta_2': 8.0\n",
    "}\n",
    "INITIAL_PARAMS.update(FIXED_PARAMS) # Combine initial optimizable parameters with fixed ones.\n",
    "\n",
    "# ==========================================\n",
    "# 2. Browser Automation Functions (Selenium Control)\n",
    "# ==========================================\n",
    "\n",
    "def create_claude():\n",
    "    \"\"\"\n",
    "    Creates and initializes a Chrome browser instance using undetected_chromedriver\n",
    "    for interacting with Claude.ai. It includes anti-detection measures and\n",
    "    prompts the user for manual login.\n",
    "    \n",
    "    Returns:\n",
    "        driver: An initialized Selenium WebDriver object for Chrome.\n",
    "    \"\"\"\n",
    "    options = uc.ChromeOptions()\n",
    "    # Spoof User-Agent to mimic a regular browser.\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\")\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled') # Prevents detection as an automated tool.\n",
    "    options.add_argument('--no-sandbox') # Required for running Chrome in some environments (e.g., Docker).\n",
    "    options.add_argument('--disable-dev-shm-usage') # Workaround for Docker environments.\n",
    "    \n",
    "    print(f\"Launching browser, driver path: {CHROMEDRIVER_PATH}\")\n",
    "    # Initialize the undetected_chromedriver with specified service and options.\n",
    "    driver = uc.Chrome(service=Service(CHROMEDRIVER_PATH), options=options)\n",
    "    \n",
    "    # Further hide webdriver properties to prevent detection.\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    driver.get(\"https://claude.ai/new\") # Navigate to Claude's new chat interface.\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"【Attention】Browser has been opened.\")\n",
    "    print(\"1. Please manually log in to your Claude account in the browser.\")\n",
    "    print(\"2. After successful login and seeing the chat interface, press Enter below to continue...\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    input(\">>> After logging in, press Enter to continue: \") # Waits for user to confirm manual login.\n",
    "    \n",
    "    time.sleep(2) # Small delay after user input.\n",
    "    return driver\n",
    "\n",
    "def wait_claude(driver):\n",
    "    \"\"\"\n",
    "    Waits for Claude to finish generating its response.\n",
    "    It works by detecting the presence and then disappearance of a \"stop generating\" button.\n",
    "    \n",
    "    Args:\n",
    "        driver: The Selenium WebDriver object.\n",
    "    \n",
    "    Raises:\n",
    "        TimeoutException: If Claude's response takes longer than 10 minutes.\n",
    "    \"\"\"\n",
    "    # Note: If your Claude interface is in English, change 'aria-label' to \"Stop generating\" or similar.\n",
    "    stop_button_selector = 'button[aria-label=\"応答を停止\"]' # CSS selector for the stop generating button.\n",
    "    \n",
    "    # Phase 1: Wait for the \"stop\" button to appear (confirming generation has started).\n",
    "    try:\n",
    "        WebDriverWait(driver, 20).until( # Wait up to 20 seconds.\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, stop_button_selector))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(\"Warning: 'Stop generating' button not detected. Claude might not have started generating or responded extremely quickly.\")\n",
    "        return # Continue if button doesn't appear, assuming response was fast.\n",
    "\n",
    "    # Phase 2: Wait for the \"stop\" button to disappear (confirming generation has ended).\n",
    "    try:\n",
    "        # Wait up to 600 seconds (10 minutes) for Claude to finish.\n",
    "        WebDriverWait(driver, 600).until_not(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, stop_button_selector))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        raise TimeoutException(\"Waiting for Claude's response timed out (exceeded 10 minutes)!\")\n",
    "\n",
    "def prompting_claude(prompt, driver):\n",
    "    \"\"\"\n",
    "    Sends a given prompt to Claude and retrieves its latest response.\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): The text content to send to Claude.\n",
    "        driver: The Selenium WebDriver object.\n",
    "        \n",
    "    Returns:\n",
    "        str: The text content of Claude's reply, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Locate the input textbox and enter the prompt text.\n",
    "        input_selector = 'div[role=\"textbox\"]' # CSS selector for the chat input box.\n",
    "        input_element = WebDriverWait(driver, 20).until( # Wait for the input element to be present.\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, input_selector))\n",
    "        )\n",
    "        input_element.click() # Click to ensure the element is in focus.\n",
    "        input_element.clear() # Clear any pre-existing text.\n",
    "        \n",
    "        # Simulate human-like typing effect (to avoid bot detection).\n",
    "        # Adjust sleep time if the prompt is very long.\n",
    "        for char in prompt:\n",
    "            input_element.send_keys(char) # Type character by character.\n",
    "            time.sleep(random.uniform(0.001, 0.005)) # Short random delay between characters.\n",
    "        \n",
    "        # 2. Locate and click the send button.\n",
    "        # Note: If the interface is in English, change 'aria-label' to \"Send Message\".\n",
    "        send_button_selector = 'button[aria-label=\"メッセージを送信\"]:not([disabled])' # CSS selector for the send button.\n",
    "        send_button = WebDriverWait(driver, 10).until( # Wait for the send button to be clickable.\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, send_button_selector))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", send_button) # Use JavaScript click to ensure reliability.\n",
    "        \n",
    "        # 3. Wait for Claude to finish generating its response.\n",
    "        wait_claude(driver)\n",
    "        \n",
    "        # 4. Retrieve the latest response.\n",
    "        # 'data-test-render-count=\"1\"' often points to the latest rendered message,\n",
    "        # but Claude's UI updates might make this selector unstable.\n",
    "        final_response_selector = 'div[data-test-render-count=\"1\"] .standard-markdown'\n",
    "        \n",
    "        try:\n",
    "            final_response_element = WebDriverWait(driver, 30).until( # Wait for the final response element.\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, final_response_selector))\n",
    "            )\n",
    "        except TimeoutException:\n",
    "            print(\"Warning: Could not locate latest response using data-test-render-count, trying fallback method...\")\n",
    "            # Fallback method: Get all response bubbles and take the last one.\n",
    "            all_responses = driver.find_elements(By.CSS_SELECTOR, 'div[data-is-response=\"true\"]')\n",
    "            if all_responses:\n",
    "                return all_responses[-1].text # Return the text of the last response bubble.\n",
    "            else:\n",
    "                return None # No responses found.\n",
    "\n",
    "        return final_response_element.text # Return the text content of the latest response.\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during Claude interaction: {e}\")\n",
    "        return None\n",
    "\n",
    "def close_claude(driver):\n",
    "    \"\"\"\n",
    "    Closes the browser window and quits the WebDriver session to release resources.\n",
    "    \n",
    "    Args:\n",
    "        driver: The Selenium WebDriver object.\n",
    "    \"\"\"\n",
    "    if driver: # Check if the driver object exists.\n",
    "        try:\n",
    "            driver.close() # Close the current window.\n",
    "            driver.quit()  # Quit the browser application.\n",
    "        except:\n",
    "            pass # Ignore errors during closing, as it might already be closed.\n",
    "\n",
    "# ==========================================\n",
    "# 3. LLM Management Class (Connecting RRI with Browser)\n",
    "# ==========================================\n",
    "\n",
    "class LLM_Manager:\n",
    "    \"\"\"\n",
    "    Manages the interaction logic with the Large Language Model (LLM) via the browser,\n",
    "    including constructing prompts, calling browser automation functions, and parsing\n",
    "    the LLM's responses.\n",
    "    \"\"\"\n",
    "    def __init__(self, prompt_path, driver):\n",
    "        \"\"\"\n",
    "        Initializes the LLM_Manager.\n",
    "        \n",
    "        Args:\n",
    "            prompt_path (str): Path to the initial prompt file.\n",
    "            driver: The Selenium WebDriver object.\n",
    "        \"\"\"\n",
    "        self.prompt_path = prompt_path\n",
    "        self.driver = driver\n",
    "        self.base_prompt = self._read_prompt() # Reads the initial prompt from file.\n",
    "        self.history = [] # Stores interaction history, though not explicitly used for chat history in prompt building in this version.\n",
    "\n",
    "    def _read_prompt(self):\n",
    "        \"\"\"\n",
    "        Reads the initial prompt content from the specified file path.\n",
    "        \n",
    "        Returns:\n",
    "            str: The content of the prompt file, or an empty string if not found.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.prompt_path):\n",
    "            print(f\"Error: {self.prompt_path} not found.\")\n",
    "            return \"\"\n",
    "        with open(self.prompt_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "\n",
    "    def parse_response(self, response_text):\n",
    "        \"\"\"\n",
    "        Parses the text response from the LLM to extract a list of parameter sets.\n",
    "        It supports extracting Python list formats from Markdown code blocks\n",
    "        (e.g., ```json[...]``` or ```python[...]```) or from plain text.\n",
    "        \n",
    "        Args:\n",
    "            response_text (str): The raw text response received from Claude.\n",
    "            \n",
    "        Returns:\n",
    "            list: A list of lists, where each inner list represents a set of parameters.\n",
    "                  Returns an empty list if parsing fails or the format is incorrect.\n",
    "        \"\"\"\n",
    "        if not response_text:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # 1. Attempt to extract content within ```json or ```python code blocks.\n",
    "            match = re.search(r\"```(?:json|python)?(.*?)```\", response_text, re.DOTALL)\n",
    "            if match:\n",
    "                clean_text = match.group(1).strip()\n",
    "            else:\n",
    "                # 2. If no code block, try to find the outermost [[ ... ]] for a list of lists.\n",
    "                start = response_text.find('[[')\n",
    "                end = response_text.rfind(']]') + 2\n",
    "                if start != -1 and end != -1:\n",
    "                    clean_text = response_text[start:end]\n",
    "                else:\n",
    "                    clean_text = response_text.strip() # If not found, take the whole text.\n",
    "            \n",
    "            # 3. Safely evaluate the extracted string into a Python object.\n",
    "            params_list = ast.literal_eval(clean_text)\n",
    "            \n",
    "            # Validate that the parsed object is a non-empty list of lists.\n",
    "            if isinstance(params_list, list) and len(params_list) > 0 and isinstance(params_list[0], list):\n",
    "                return params_list\n",
    "            else:\n",
    "                print(\"Parsing failed: Response content is not in a 2D list format.\")\n",
    "                return []\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing LLM response: {e}\")\n",
    "            print(f\"Original content snippet: {response_text[:100]}...\") # Print a snippet for debugging.\n",
    "            return []\n",
    "\n",
    "    def get_next_params(self, last_formatted_list=None, last_params_values=None):\n",
    "        \"\"\"\n",
    "        Constructs the prompt for Claude and sends it to get the next set of parameters.\n",
    "        For the first round, it sends the base prompt. For subsequent rounds, it\n",
    "        includes feedback from the previous model evaluation.\n",
    "        \n",
    "        Args:\n",
    "            last_formatted_list (list, optional): A list of NSE scores from the previous round,\n",
    "                                                 formatted for readability. Defaults to None for the first round.\n",
    "            last_params_values (list, optional): A list of parameter sets used in the previous round.\n",
    "                                                Defaults to None for the first round.\n",
    "                                                \n",
    "        Returns:\n",
    "            list: A list of new parameter sets proposed by Claude.\n",
    "        \"\"\"\n",
    "        \n",
    "        if last_formatted_list is None:\n",
    "            # First round: Send only the base prompt to get initial parameter suggestions.\n",
    "            current_prompt = self.base_prompt\n",
    "        else:\n",
    "            # Subsequent rounds: Append feedback data to the base prompt.\n",
    "            feedback_str = \"\\n\\n### Feedback from Previous Round ###\\n\"\n",
    "            feedback_str += \"Please analyze the following parameter combinations and their corresponding NSE scores (higher scores are better):\\n\"\n",
    "            \n",
    "            # Iterate through the previous round's scores and parameter sets to build feedback.\n",
    "            for i, (score, params) in enumerate(zip(last_formatted_list, last_params_values)):\n",
    "                feedback_str += f\"Set {i+1}: Parameters={params} -> NSE Score={score}\\n\"\n",
    "            \n",
    "            feedback_str += \"\\nBased on the above results, please generate a new list of better candidate parameters.\\n\"\n",
    "            feedback_str += \"Please **only** output the list format, without any explanatory text. Format example: [[0.1, ...], [0.2, ...]]\"\n",
    "            \n",
    "            # Concatenate the base prompt and the feedback string.\n",
    "            current_prompt = self.base_prompt + feedback_str\n",
    "\n",
    "        print(f\"Sending Prompt to Claude (length: {len(current_prompt)} characters)...\")\n",
    "        # Call the browser automation function to send the prompt and get Claude's response.\n",
    "        response_text = prompting_claude(current_prompt, self.driver)\n",
    "        \n",
    "        if response_text:\n",
    "            print(\"\\n--- Claude's Response ---\")\n",
    "            # Print the first 200 characters of the response for debugging/monitoring.\n",
    "            print(response_text[:200] + \"...\" if len(response_text)>200 else response_text)\n",
    "            print(\"-------------------\\n\")\n",
    "            \n",
    "        # Parse Claude's response to extract the new parameter values.\n",
    "        new_values = self.parse_response(response_text)\n",
    "        return new_values\n",
    "\n",
    "# ==========================================\n",
    "# 4. RRI Model Helper Functions (File I/O & Calculation)\n",
    "# ==========================================\n",
    "\n",
    "def format_fortran_line(par_name, params_dict, num_landuse):\n",
    "    \"\"\"\n",
    "    Formats a parameter line for the RRI model's Fortran input file.\n",
    "    It takes a base parameter name and retrieves values for different land uses\n",
    "    from a dictionary, formatting them as double-precision (e.g., \"0.123456d0\").\n",
    "    \n",
    "    Args:\n",
    "        par_name (str): The base name of the parameter (e.g., \"# ns_slope\").\n",
    "        params_dict (dict): A dictionary containing all RRI model parameters.\n",
    "        num_landuse (int): The number of land-use types in the RRI model.\n",
    "        \n",
    "    Returns:\n",
    "        str: The formatted string for the RRI_Input.txt file, or an empty string if error.\n",
    "    \"\"\"\n",
    "    values = []\n",
    "    base_name = par_name[2:].strip() # Remove \"# \" prefix.\n",
    "    for j in range(num_landuse):\n",
    "        param_key = f\"{base_name}_{j+1}\" # Construct parameter key (e.g., \"ns_slope_1\").\n",
    "        if param_key in params_dict:\n",
    "            values.append(f\"{params_dict[param_key]:.6f}d0\") # Format as double-precision Fortran literal.\n",
    "        else:\n",
    "            print(f\"Error: Parameter {param_key} not found in the provided dictionary.\")\n",
    "            return \"\"\n",
    "    return '\\t'.join(values) + f\"      # {base_name}\\n\" # Join values with tabs and add comment.\n",
    "\n",
    "def modify_rri_input_file(params_dict, rain_file_path, duration_hours):\n",
    "    \"\"\"\n",
    "    Modifies the `RRI_Input.txt` file with new rainfall data path, simulation duration,\n",
    "    and updated RRI model parameters from `params_dict`.\n",
    "    \n",
    "    Args:\n",
    "        params_dict (dict): A dictionary of RRI model parameters to be updated.\n",
    "        rain_file_path (str): The filename of the rainfall data to use for this simulation.\n",
    "        duration_hours (int): The total simulation duration in hours.\n",
    "        \n",
    "    Returns:\n",
    "        bool: True if the file was successfully modified, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(PATHS['rri_input'], 'r') as f:\n",
    "            lines = f.readlines() # Read all lines from the RRI input template file.\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {PATHS['rri_input']} not found.\")\n",
    "        return False\n",
    "    \n",
    "    full_rain_path = os.path.join(PATHS['rain_folder'], rain_file_path) # Construct full path for rain data.\n",
    "    \n",
    "    # Modify specific lines in the RRI_Input.txt file.\n",
    "    lines[2] = f\"{full_rain_path}\\n\" # Update rainfall data path.\n",
    "    lines[9] = f\"{duration_hours}    # lasth(hour)\\n\" # Update simulation end time.\n",
    "    lines[12] = f\"{duration_hours}    # outnum [-]\\n\" # Update output steps (often matches duration).\n",
    "\n",
    "    num_landuse = None\n",
    "    # Find the number of land-use types from the input file.\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"# num_of_landuse\" in line:\n",
    "            num_landuse = int(lines[i].split('#')[0].strip())\n",
    "            break\n",
    "            \n",
    "    if num_landuse is None:\n",
    "        print(\"Error: Could not find 'num_of_landuse' in RRI_Input.txt.\")\n",
    "        return False\n",
    "\n",
    "    # List of parameters that need multi-landuse formatting.\n",
    "    target_params = [\"# ns_slope\", \"# soildepth\", \"# gammaa\", \"# ksv\", \n",
    "                     \"# faif\", \"# ka\", \"# gammam\", \"# beta\"]\n",
    "    \n",
    "    # Iterate through lines to update parameter values.\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"# ns_river\" in line and 'ns_river' in params_dict:\n",
    "            lines[i] = f\"{params_dict['ns_river']:.6f}d0     # ns_river\\n\" # Update single-value parameter.\n",
    "        else:\n",
    "            for tag in target_params: # For multi-landuse parameters.\n",
    "                if tag in line:\n",
    "                    lines[i] = format_fortran_line(tag, params_dict, num_landuse) # Use helper to format.\n",
    "                    break\n",
    "    \n",
    "    # Write the modified lines back to the RRI_Input.txt file.\n",
    "    with open(PATHS['rri_input'], 'w') as f:\n",
    "        f.writelines(lines)\n",
    "    return True\n",
    "\n",
    "def get_raster_info(tif_path):\n",
    "    \"\"\"\n",
    "    Reads essential metadata (dimensions, geotransform) from a GeoTIFF file.\n",
    "    \n",
    "    Args:\n",
    "        tif_path (str): Path to the GeoTIFF file.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing 'cols' (number of columns), 'rows' (number of rows),\n",
    "              and 'geotransform' (GDAL geotransform tuple).\n",
    "              \n",
    "    Raises:\n",
    "        Exception: If the GeoTIFF file cannot be opened.\n",
    "    \"\"\"\n",
    "    ds = gdal.Open(tif_path) # Open the GeoTIFF dataset.\n",
    "    if ds is None: raise Exception(f\"Cannot open {tif_path}\")\n",
    "    return {'cols': ds.RasterXSize, 'rows': ds.RasterYSize, 'geotransform': ds.GetGeoTransform()}\n",
    "\n",
    "def lonlat_to_xy(lon, lat, geotransform):\n",
    "    \"\"\"\n",
    "    Converts geographic coordinates (longitude, latitude) to raster pixel coordinates (column, row).\n",
    "    \n",
    "    Args:\n",
    "        lon (float): Longitude.\n",
    "        lat (float): Latitude.\n",
    "        geotransform (tuple): GDAL geotransform tuple (top-left x, w-e pixel resolution,\n",
    "                              row rotation, top-left y, n-s pixel resolution, col rotation).\n",
    "                              \n",
    "    Returns:\n",
    "        tuple: (x, y) where x is column index and y is row index.\n",
    "    \"\"\"\n",
    "    # Inverse geotransform formula to convert geo coordinates to pixel coordinates.\n",
    "    x = int((lon - geotransform[0]) / geotransform[1])\n",
    "    y = int((lat - geotransform[3]) / geotransform[5])\n",
    "    return x, y\n",
    "\n",
    "def read_out_file(out_file):\n",
    "    \"\"\"\n",
    "    Reads a numerical matrix from a plain text .out file (RRI output).\n",
    "    \n",
    "    Args:\n",
    "        out_file (str): Path to the .out file.\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: A NumPy array representing the data matrix, or an empty array if loading fails.\n",
    "    \"\"\"\n",
    "    try: return np.loadtxt(out_file) # Use numpy to load data efficiently.\n",
    "    except: return np.array([]) # Return empty array on error.\n",
    "\n",
    "def extract_time_series(lon, lat, tif_path, out_folder, out_prefix):\n",
    "    \"\"\"\n",
    "    Extracts a time series of values for a specific geographic coordinate\n",
    "    from a sequence of RRI model output files (e.g., qr_1.out, qr_2.out).\n",
    "    \n",
    "    Args:\n",
    "        lon (float): Longitude of the observation point.\n",
    "        lat (float): Latitude of the observation point.\n",
    "        tif_path (str): Path to the DEM GeoTIFF file (for coordinate conversion).\n",
    "        out_folder (str): Directory where RRI output files are stored.\n",
    "        out_prefix (str): Prefix of the RRI output files.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing 'time_steps' and 'values' lists,\n",
    "              or None if raster info cannot be obtained.\n",
    "    \"\"\"\n",
    "    try: raster_info = get_raster_info(tif_path)\n",
    "    except: return None # Return None if DEM info can't be read.\n",
    "    x, y = lonlat_to_xy(lon, lat, raster_info['geotransform']) # Convert geo to pixel coordinates.\n",
    "    \n",
    "    # Regex pattern to match RRI output files and extract their time step number.\n",
    "    pattern = re.compile(rf'{out_prefix}_(\\d+)\\.out')\n",
    "    # List and sort all relevant output files by their time step.\n",
    "    all_files = sorted([os.path.join(out_folder, f) for f in os.listdir(out_folder) if pattern.match(f)],\n",
    "                       key=lambda x: int(pattern.search(os.path.basename(x)).group(1)))\n",
    "    \n",
    "    values = []\n",
    "    steps = []\n",
    "    for fpath in all_files:\n",
    "        data = read_out_file(fpath) # Read data for each time step.\n",
    "        # Check if data is valid and coordinates are within bounds.\n",
    "        if len(data) > 0 and y < data.shape[0] and x < data.shape[1]:\n",
    "            values.append(data[y, x]) # Extract value at the specified pixel.\n",
    "        else:\n",
    "            values.append(np.nan) # Append NaN if data is invalid or out of bounds.\n",
    "        steps.append(int(pattern.search(os.path.basename(fpath)).group(1))) # Store the time step.\n",
    "    return {'time_steps': steps, 'values': values}\n",
    "\n",
    "def get_simulated_values():\n",
    "    \"\"\"\n",
    "    Orchestrates the extraction of simulated time series data for all predefined\n",
    "    observation locations from RRI model outputs and cleans up temporary files.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: A NumPy array of simulated values (assuming a single observation point,\n",
    "                       or concatenating if multiple, based on `results[0]['value']` structure).\n",
    "                       Returns an empty array if no results are found.\n",
    "    \"\"\"\n",
    "    os.makedirs(PATHS['result_folder'], exist_ok=True) # Ensure the results folder exists.\n",
    "    results = []\n",
    "    # Loop through all defined observation locations.\n",
    "    for lon, lat in LOCATIONS:\n",
    "        ts = extract_time_series(lon, lat, PATHS['dem'], PATHS['out_folder'], PATHS['out_prefix'])\n",
    "        if ts: results.append(pd.DataFrame({'value': ts['values']})) # If successful, store as DataFrame.\n",
    "    \n",
    "    # Clean up the 'out' folder by removing temporary RRI output files.\n",
    "    for f in os.listdir(PATHS['out_folder']):\n",
    "        try: os.remove(os.path.join(PATHS['out_folder'], f))\n",
    "        except: pass\n",
    "        \n",
    "    if not results: return np.array([]) # Return empty array if no simulation results were extracted.\n",
    "    return results[0]['value'].values # Return values from the first (and typically only) observation point.\n",
    "\n",
    "def update_params_dict(params_dict, new_values):\n",
    "    \"\"\"\n",
    "    Updates a given RRI parameter dictionary with new values,\n",
    "    skipping any parameters defined as 'fixed'.\n",
    "    \n",
    "    Args:\n",
    "        params_dict (dict): The base dictionary of RRI parameters (e.g., INITIAL_PARAMS).\n",
    "        new_values (list): A list of new parameter values received from the LLM.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A new dictionary with updated parameters, or None if the number of\n",
    "              new values does not match the number of optimizable parameters.\n",
    "    \"\"\"\n",
    "    # Keys that should not be updated (fixed parameters).\n",
    "    skip_keys = ['gammaa_1', 'gammaa_2', 'ksv_1', 'ksv_2', 'faif_1', 'faif_2']\n",
    "    # Identify keys that are eligible for update.\n",
    "    update_keys = [key for key in params_dict.keys() if key not in skip_keys]\n",
    "    \n",
    "    if len(new_values) != len(update_keys):\n",
    "        print(f\"Warning: Parameter count mismatch. Expected {len(update_keys)} values, but received {len(new_values)}.\")\n",
    "        return None \n",
    "    \n",
    "    updated_dict = params_dict.copy() # Create a copy to avoid modifying the original.\n",
    "    # Assign new values to the optimizable parameters.\n",
    "    for key, value in zip(update_keys, new_values):\n",
    "        updated_dict[key] = value\n",
    "    return updated_dict\n",
    "\n",
    "def run_model_and_evaluate(params_dict):\n",
    "    \"\"\"\n",
    "    Runs a complete RRI model evaluation cycle for a given set of parameters,\n",
    "    covering multiple rainfall events, and calculates the Nash-Sutcliffe Efficiency (NSE) score.\n",
    "    \n",
    "    Args:\n",
    "        params_dict (dict): The dictionary of RRI model parameters to use for the simulation.\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (average_NSE, list_of_individual_NSE_scores)\n",
    "               average_NSE is the mean of valid NSE scores across all events.\n",
    "               list_of_individual_NSE_scores contains NSE for each event.\n",
    "               Returns -999.0 for NSE if calculation fails.\n",
    "    \"\"\"\n",
    "    nse_list = []\n",
    "    # Iterate through each defined rainfall event.\n",
    "    for index, (rain_file, duration) in enumerate(RAIN_EVENTS):\n",
    "        # Modify the RRI input file for the current event's rainfall and parameters.\n",
    "        if not modify_rri_input_file(params_dict, rain_file, duration):\n",
    "            nse_list.append(-999.0); continue # Append error code if input file modification fails.\n",
    "        \n",
    "        try:\n",
    "            # Execute the RRI Fortran model executable.\n",
    "            # `check=True` raises an exception for non-zero exit codes.\n",
    "            # `stdout` and `stderr` are captured to avoid console clutter.\n",
    "            subprocess.run([PATHS['rri_exe']], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"    Exe execution failed for event {index+1}: {e.stderr.decode().strip()}\")\n",
    "            nse_list.append(-999.0); continue # Append error code if RRI execution fails.\n",
    "        \n",
    "        sim_data = get_simulated_values() # Extract simulated discharge data.\n",
    "        \n",
    "        try:\n",
    "            # Read observed discharge data for the current event from the Excel file.\n",
    "            obs_df = pd.read_excel(PATHS['obs_data'])\n",
    "            obs_values = obs_df[index + 1].dropna().values # Get data for current event column, drop NaNs.\n",
    "        except Exception as e:\n",
    "            print(f\"    Obs data read failed for event {index+1}: {e}\")\n",
    "            nse_list.append(-999.0); continue # Append error code if observed data reading fails.\n",
    "            \n",
    "        if len(sim_data) != len(obs_values) or len(obs_values) == 0:\n",
    "            print(\"    Data length mismatch or no observed data. Cannot calculate NSE.\")\n",
    "            nse_list.append(-999.0); continue # Append error code if data lengths don't match or no obs data.\n",
    "            \n",
    "        # Calculate Nash-Sutcliffe Efficiency (NSE).\n",
    "        mean_obs = np.mean(obs_values)\n",
    "        denom = np.sum((obs_values - mean_obs) ** 2)\n",
    "        # Avoid division by zero; if denominator is zero, NSE is undefined or typically set to a very low value.\n",
    "        nse = 1 - np.sum((obs_values - sim_data) ** 2) / denom if denom != 0 else -999.0\n",
    "        nse_list.append(nse)\n",
    "\n",
    "    # Calculate the average NSE, excluding any error values (-999.0).\n",
    "    valid_nses = [n for n in nse_list if n > -100] # Filter out error codes.\n",
    "    avg_nse = np.mean(valid_nses) if valid_nses else -999.0 # Calculate mean if valid scores exist.\n",
    "    return avg_nse, nse_list\n",
    "\n",
    "# ==========================================\n",
    "# 5. Main Program Entry\n",
    "# ==========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # The following commented-out block was used for initial testing\n",
    "    # of the RRI model evaluation logic without involving the browser-based LLM.\n",
    "    '''\n",
    "    ## Original test, without using LLM in browser\n",
    "    # new_values represents a batch of parameter sets that would typically come from the LLM.\n",
    "    new_values = [\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.09, 0.03, 0.07, 0.04, 2.51, 2.11],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.095, 0.03, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.275, 0.185, 0.09, 0.03, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.09, 0.03, 0.065, 0.045, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.09, 0.03, 0.075, 0.055, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.50, 2.12],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.49, 2.09],\n",
    "    [0.10, 0.055, 0.03, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.025, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.105, 0.05, 0.03, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.095, 0.05, 0.03, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.09, 0.035, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.09, 0.025, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.085, 0.03, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.285, 0.195, 0.09, 0.03, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.275, 0.185, 0.09, 0.03, 0.065, 0.045, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.095, 0.03, 0.075, 0.055, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.52, 2.13],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.48, 2.08],\n",
    "    [0.10, 0.05, 0.03, 0.278, 0.188, 0.092, 0.032, 0.072, 0.052, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.282, 0.192, 0.088, 0.028, 0.068, 0.048, 2.50, 2.10],\n",
    "    [0.102, 0.052, 0.032, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.098, 0.048, 0.028, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.50, 2.10],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.51, 2.11],\n",
    "    [0.10, 0.05, 0.03, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.50, 2.09],\n",
    "    [0.10, 0.05, 0.03, 0.281, 0.191, 0.091, 0.031, 0.071, 0.051, 2.51, 2.11],\n",
    "    [0.10, 0.05, 0.03, 0.279, 0.189, 0.089, 0.029, 0.069, 0.049, 2.49, 2.09],\n",
    "    [0.101, 0.051, 0.031, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.51, 2.11],\n",
    "    [0.099, 0.049, 0.029, 0.28, 0.19, 0.09, 0.03, 0.07, 0.05, 2.49, 2.09]\n",
    "    ]\n",
    "    out_avg_nse = []        # List to store average NSE for each parameter set.\n",
    "    out_detailed_nse = []   # List to store detailed NSE for each event for each parameter set.\n",
    "    \n",
    "    current_params = INITIAL_PARAMS.copy() # Start with initial parameters.\n",
    "    \n",
    "    print(\"Starting Batch Evaluation from LLM Parameters...\")\n",
    "    \n",
    "    for ii, val_list in enumerate(new_values):\n",
    "        print(f\"\\nProcessing Set {ii+1}/{len(new_values)}...\")\n",
    "        \n",
    "        try:\n",
    "            updated_dict = update_params_dict(current_params, val_list) # Update parameters for this set.\n",
    "            \n",
    "            avg_nse, detailed_nse = run_model_and_evaluate(updated_dict) # Run model and evaluate.\n",
    "            \n",
    "            out_avg_nse.append(avg_nse)        # Store results.\n",
    "            out_detailed_nse.append(detailed_nse)\n",
    "            \n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping Set {ii+1} due to error: {e}\")\n",
    "            out_avg_nse.append(-999.0)\n",
    "            out_detailed_nse.append([])\n",
    "\n",
    "    formatted_list = [round(num, 3) for num in out_avg_nse] # Format average NSE for output.\n",
    "    \n",
    "    print('\\n================ RESULTS ================')\n",
    "    print('Detailed NSE List per set:')\n",
    "    print(out_detailed_nse)\n",
    "    print('-----------------------------------------')\n",
    "    print('Formatted Average NSE List (for LLM):')\n",
    "    print(formatted_list)\n",
    "    print('=========================================')\n",
    "    ''' \n",
    "    \n",
    "    driver = None # Initialize driver to None, so it can be safely closed in finally block.\n",
    "    try:\n",
    "        # 1. Launch the browser and prompt for manual login to Claude.\n",
    "        driver = create_claude()\n",
    "        \n",
    "        # 2. Initialize the LLM_Manager, which handles communication with Claude.\n",
    "        llm = LLM_Manager(PATHS['prompt_file'], driver)\n",
    "        \n",
    "        # 3. Main optimization loop.\n",
    "        current_formatted_list = None # Stores NSE scores from the previous round, used as feedback for Claude.\n",
    "        current_values_list = None    # Stores parameter sets from the previous round, used as feedback for Claude.\n",
    "        best_overall_nse = -999.0     # Tracks the highest NSE score achieved across all rounds.\n",
    "        best_overall_params = []      # Stores the parameter set that yielded the `best_overall_nse`.\n",
    "\n",
    "        print(f\"Starting optimization process. Maximum rounds: {MAX_ROUNDS}\")\n",
    "\n",
    "        for round_idx in range(MAX_ROUNDS):\n",
    "            print(f\"\\n\" + \"=\"*40)\n",
    "            print(f\" ROUND {round_idx + 1} / {MAX_ROUNDS}\")\n",
    "            print(f\"=\"*40)\n",
    "            \n",
    "            # 3.1 Get a batch of new candidate parameter sets from Claude.\n",
    "            # Passes the previous round's performance (NSE scores and parameter values) as feedback.\n",
    "            new_values_batch = llm.get_next_params(current_formatted_list, current_values_list)\n",
    "            \n",
    "            if not new_values_batch:\n",
    "                print(\"Did not receive valid parameters from Claude, stopping loop.\")\n",
    "                break # Exit if Claude doesn't provide new parameters.\n",
    "                \n",
    "            print(f\"LLM generated {len(new_values_batch)} sets of parameters, starting evaluation...\")\n",
    "            \n",
    "            # Variables to store results for the current round.\n",
    "            round_avg_scores = []\n",
    "            round_detailed_scores = []\n",
    "            \n",
    "            # 3.2 Evaluate each parameter set in the batch.\n",
    "            for i, val_list in enumerate(new_values_batch):\n",
    "                print(f\"  Eval Set {i+1}: {val_list}\")\n",
    "                \n",
    "                # Update the base RRI parameter dictionary with the current candidate values.\n",
    "                current_params = update_params_dict(INITIAL_PARAMS, val_list)\n",
    "                if current_params is None:\n",
    "                    round_avg_scores.append(-999.0) # Mark as error if update fails.\n",
    "                    continue\n",
    "\n",
    "                # Run the RRI model and calculate NSE for the updated parameters.\n",
    "                avg_nse, detailed = run_model_and_evaluate(current_params)\n",
    "                print(f\"    -> Avg NSE: {avg_nse:.4f}\")\n",
    "                \n",
    "                round_avg_scores.append(avg_nse)      # Store the average NSE for this parameter set.\n",
    "                round_detailed_scores.append(detailed) # Store detailed NSE for this set.\n",
    "                \n",
    "                # Update the overall best performance if a better NSE is found.\n",
    "                if avg_nse > best_overall_nse:\n",
    "                    best_overall_nse = avg_nse\n",
    "                    best_overall_params = val_list\n",
    "                    print(f\"    *** New best value found: {best_overall_nse:.4f} ***\")\n",
    "\n",
    "            # 3.3 Prepare data for the next round's feedback.\n",
    "            current_values_list = new_values_batch # The parameters used in this round.\n",
    "            # Format the average NSE scores to 3 decimal places for clearer feedback to Claude.\n",
    "            current_formatted_list = [round(num, 3) for num in round_avg_scores]\n",
    "            \n",
    "            print(f\"\\nEnd of Round {round_idx + 1}.\")\n",
    "            print(f\"Scores list for feedback: {current_formatted_list}\")\n",
    "            \n",
    "            # Introduce a pause to avoid frequent requests to Claude.\n",
    "            print(f\"Waiting for {PAUSE_SECONDS} seconds...\")\n",
    "            time.sleep(PAUSE_SECONDS)\n",
    "\n",
    "        # 4. Final output after the optimization loop completes.\n",
    "        print(\"\\n\" + \"=\"*40)\n",
    "        print(\" Optimization Finished \")\n",
    "        print(\"=\"*40)\n",
    "        print(f\"Best NSE achieved: {best_overall_nse:.6f}\")\n",
    "        print(f\"Best parameters: {best_overall_params}\")\n",
    "        \n",
    "        # Save the best results to a file.\n",
    "        with open('final_best_params.txt', 'w') as f:\n",
    "            f.write(f\"Best NSE: {best_overall_nse}\\n\")\n",
    "            f.write(f\"Params: {best_overall_params}\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An unhandled exception occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc() # Print full traceback for debugging.\n",
    "        \n",
    "    finally:\n",
    "        print(\"Closing browser...\")\n",
    "        close_claude(driver) # Ensure the browser is closed even if errors occur."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leafmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
