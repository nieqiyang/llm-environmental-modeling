{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb4ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Project: RRI Model Parameter Calibration using SCE-UA\n",
    "Description:\n",
    "    This script implements the Shuffled Complex Evolution (SCE-UA) global optimization \n",
    "    algorithm to automatically calibrate sensitive parameters for the Rainfall-Runoff-Inundation (RRI) model.\n",
    "\n",
    "Overall Workflow:\n",
    "    1. Configuration: Define file paths, observation coordinates, rainfall events, parameter boundaries, and fixed parameters.\n",
    "    2. Initialization: Instantiate the SCE-UA optimizer with hyperparameters (population size, number of complexes, etc.).\n",
    "    3. Optimization Loop:\n",
    "       a. Sampling: Generate an initial population or evolve offspring within the parameter space.\n",
    "       b. Model Execution (run_model_and_evaluate):\n",
    "          - Update 'RRI_Input.txt' with the current parameter set.\n",
    "          - Execute the external RRI model (.exe).\n",
    "          - Read the generated raster output files.\n",
    "          - Extract time-series data at specific observation coordinates.\n",
    "          - Compare simulated results with observed data (Excel).\n",
    "          - Calculate the Nash-Sutcliffe Efficiency (NSE).\n",
    "          - Return -NSE (as the optimizer minimizes the objective function).\n",
    "       c. Evolution: Sort population, partition into complexes, evolve using CCE (Simplex method), and shuffle.\n",
    "    4. Output: Display and save the optimal parameter set and the best NSE score.\n",
    "\n",
    "Notes:\n",
    "    - Requires the GDAL library for raster data processing.\n",
    "    - Ensure the RRI executable and input file formats are correct before running.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from osgeo import gdal\n",
    "\n",
    "# ==========================================\n",
    "# 1. Global Configuration & Parameters\n",
    "# ==========================================\n",
    "\n",
    "# 1.1 File Paths and Directory Settings\n",
    "PATHS = {\n",
    "    'dem': \"topo/dem_250.tif\",       # Path to DEM file, used for raster reference info\n",
    "    'out_folder': \"out\",             # Folder for raw RRI model outputs\n",
    "    'result_folder': \"results\",      # Folder to save processed results\n",
    "    'out_prefix': \"qr\",              # Prefix of RRI output files (e.g., qr_1.out)\n",
    "    'rri_exe': \"0_rri_1_4_2_6.exe\",  # RRI model executable filename\n",
    "    'rri_input': \"RRI_Input.txt\",    # Path to the main RRI configuration file\n",
    "    'obs_data': \"./results/obsQ.xlsx\", # Path to observed discharge data (Excel)\n",
    "    'rain_folder': \"./rain\"          # Folder containing rainfall data files\n",
    "}\n",
    "\n",
    "# 1.2 Observation Coordinates (Longitude, Latitude)\n",
    "# The model extracts simulation results at these locations for comparison\n",
    "LOCATIONS = [\n",
    "    # (120.5, 30.2),       # Example Location 1\n",
    "    (136.16375, 36.0081)   # Example Location 2\n",
    "]\n",
    "\n",
    "# 1.3 Rainfall Events List (Filename, Simulation Duration in Hours)\n",
    "# Used for multi-event calibration. Format: (Rainfall Filename, Duration Hours)\n",
    "RAIN_EVENTS = [\n",
    "    ('rain_merged_precipitation_20040717_to_20040723.dat', 168),\n",
    "    ('rain_merged_precipitation_20041019_to_20041022.dat', 81),\n",
    "    ('rain_merged_precipitation_20050630_to_20050709.dat', 240),\n",
    "    ('rain_merged_precipitation_20110707_to_20110711.dat', 120),\n",
    "    ('rain_merged_precipitation_20110919_to_20110926.dat', 192),\n",
    "    ('rain_merged_precipitation_20171021_to_20171028.dat', 192),\n",
    "    ('rain_merged_precipitation_20180704_to_20180711.dat', 192)\n",
    "]\n",
    "\n",
    "# 1.4 Parameters to Optimize and Boundaries (Name: [Min, Max])\n",
    "# The SCE-UA algorithm will search for optimal values within these ranges.\n",
    "# Definitions align with the specific RRI model calibration framework.\n",
    "PARAMS_BOUNDS = {\n",
    "    # River Channel Parameter\n",
    "    'ns_river':    [0.01, 0.1],       # River channel Manning’s roughness coefficient\n",
    "\n",
    "    # Land Use Type 1 (e.g., Forest)\n",
    "    'ns_slope_1':  [0.03, 1.0],       # Ground surface Manning’s roughness coefficient (Type 1)\n",
    "    'soildepth_1': [0.05, 3.0],       # Soil depth (Type 1)\n",
    "    'gammaa_1':    [0.3, 0.5],        # Soil effective porosity (Type 1)\n",
    "    'gammam_1':    [0.05, 0.49],      # Soil capillary porosity (Type 1)\n",
    "    'ka_1':        [0.01, 0.5],       # Lateral saturated hydraulic conductivity (Type 1)\n",
    "    'beta_1':      [2.0, 30.0],       # Parameter for calculating the lateral hydraulic conductivity of the unsaturated zone (Type 1)\n",
    "    \n",
    "\n",
    "    # Land Use Type 2 (e.g., Non-Forest)\n",
    "    'ns_slope_2':  [0.03, 1.0],       # Ground surface Manning’s roughness coefficient (Type 2)\n",
    "    'soildepth_2': [0.05, 3.0],       # Soil depth (Type 2)\n",
    "    'gammaa_2':    [0.3, 0.5],        # Soil effective porosity (Type 2)\n",
    "    'gammam_2':    [0.05, 0.49],      # Soil capillary porosity (Type 2)\n",
    "    'ka_2':        [0.01, 0.5],       # Lateral saturated hydraulic conductivity (Type 2)\n",
    "    'beta_2':      [2.0, 30.0],       # Parameter for calculating the lateral hydraulic conductivity of the unsaturated zone (Type 2)\n",
    "}\n",
    "\n",
    "# 1.5 Fixed Parameters (Not involved in optimization)\n",
    "# These values remain constant during the simulation runs\n",
    "FIXED_PARAMS = {\n",
    "    'ksv_1':       0.0000,            # Lateral saturated hydraulic conductivity (Type 1)\n",
    "    'ksv_2':       0.0000,            # Lateral saturated hydraulic conductivity (Type 2)\n",
    "    'faif_1':      0.0000,            # Wetting front suction head (Green-Ampt parameter) (Type 1)\n",
    "    'faif_2':      0.0000             # Wetting front suction head (Green-Ampt parameter) (Type 2)\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. SCE-UA Optimization Algorithm Class\n",
    "# ==========================================\n",
    "\n",
    "class SCEUA:\n",
    "    \"\"\"\n",
    "    Implementation of the SCE-UA (Shuffled Complex Evolution - University of Arizona) algorithm.\n",
    "    It is a heuristic global optimization method widely used in hydrological model calibration.\n",
    "    \"\"\"\n",
    "    def __init__(self, objective_function, bounds, max_evaluations=10000, num_complexes=5,\n",
    "                 points_per_complex=21, num_points=105, num_evolution_steps=21, \n",
    "                 num_offspring=1, alpha=0.8, beta=0.45):\n",
    "        \"\"\"\n",
    "        Initialize SCE-UA algorithm parameters.\n",
    "        \n",
    "        Args:\n",
    "            objective_function (callable): The function to minimize. Takes parameters, returns scalar.\n",
    "            bounds (list/array): Parameter boundaries [[min, max], ...].\n",
    "            max_evaluations (int): Maximum number of function evaluations allowed.\n",
    "            num_complexes (int): Number of complexes (p).\n",
    "            points_per_complex (int): Number of points in each complex (m).\n",
    "            num_points (int): Total population size (s = p * m).\n",
    "            num_evolution_steps (int): Number of evolution steps within each complex.\n",
    "            num_offspring (int): Number of offspring generated per step.\n",
    "            alpha (float): Reflection coefficient for the simplex method.\n",
    "            beta (float): Contraction coefficient for the simplex method.\n",
    "        \"\"\"\n",
    "        self.objective_function = objective_function\n",
    "        self.bounds = np.array(bounds)\n",
    "        self.dim = len(bounds)\n",
    "        self.max_evaluations = max_evaluations\n",
    "        \n",
    "        # SCE-UA Parameters\n",
    "        self.num_complexes = num_complexes\n",
    "        self.points_per_complex = points_per_complex\n",
    "        self.num_points = num_points\n",
    "        self.num_evolution_steps = num_evolution_steps\n",
    "        self.num_offspring = num_offspring\n",
    "        self.num_parents = min(2 * self.dim + 1, self.points_per_complex)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "        # State variables\n",
    "        self.evaluations = 0\n",
    "        self.best_solution = None\n",
    "        self.best_objective = float('inf')\n",
    "        self.evolution_history = []\n",
    "    \n",
    "    def generate_initial_population(self):\n",
    "        \"\"\"Generate the initial population using random uniform sampling within bounds.\"\"\"\n",
    "        population = np.zeros((self.num_points, self.dim))\n",
    "        objectives = np.zeros(self.num_points)\n",
    "        \n",
    "        for i in range(self.dim):\n",
    "            population[:, i] = np.random.uniform(self.bounds[i, 0], self.bounds[i, 1], self.num_points)\n",
    "        \n",
    "        for i in range(self.num_points):\n",
    "            objectives[i] = self.objective_function(population[i])\n",
    "            self.evaluations += 1\n",
    "            \n",
    "            if objectives[i] < self.best_objective:\n",
    "                self.best_objective = objectives[i]\n",
    "                self.best_solution = population[i].copy()\n",
    "            self.evolution_history.append(self.best_objective)\n",
    "            \n",
    "            if self.evaluations >= self.max_evaluations:\n",
    "                break\n",
    "        \n",
    "        # Sort population by objective function value (ascending)\n",
    "        sort_indices = np.argsort(objectives)\n",
    "        return population[sort_indices], objectives[sort_indices]\n",
    "    \n",
    "    def partition_into_complexes(self, population, objectives):\n",
    "        \"\"\"\n",
    "        Partition the sorted population into multiple complexes (Shuffling).\n",
    "        Ensures each complex contains a mix of good and bad points.\n",
    "        \"\"\"\n",
    "        complexes = []\n",
    "        complex_objectives = []\n",
    "        for i in range(self.num_complexes):\n",
    "            idx = np.arange(i, self.num_points, self.num_complexes)\n",
    "            complexes.append(population[idx].copy())\n",
    "            complex_objectives.append(objectives[idx].copy())\n",
    "        return complexes, complex_objectives\n",
    "    \n",
    "    def evolve_complex(self, complex_points, complex_objectives):\n",
    "        \"\"\"\n",
    "        Execute the Competitive Complex Evolution (CCE) process.\n",
    "        Uses the Simplex method (Nelder-Mead variant) to evolve points within a complex.\n",
    "        Includes Reflection, Contraction, and Mutation steps.\n",
    "        \"\"\"\n",
    "        n = len(complex_points)\n",
    "        \n",
    "        for _ in range(self.num_evolution_steps):\n",
    "            if self.evaluations >= self.max_evaluations:\n",
    "                break\n",
    "            \n",
    "            # Select parents based on triangular probability distribution (better points have higher probability)\n",
    "            num_parents_to_select = min(self.num_parents, n)\n",
    "            weights = np.array([2 * (n + 1 - j) / (n * (n + 1)) for j in range(1, n + 1)])\n",
    "            weights = weights / np.sum(weights)\n",
    "            \n",
    "            parent_indices = np.random.choice(range(n), size=num_parents_to_select, replace=False, p=weights)\n",
    "            parent_indices = np.sort(parent_indices)\n",
    "            \n",
    "            parents = complex_points[parent_indices]\n",
    "            parent_objectives = complex_objectives[parent_indices]\n",
    "            \n",
    "            # Calculate centroid (excluding the worst point)\n",
    "            centroid = np.mean(parents[:-1], axis=0)\n",
    "            worst_point = parents[-1]\n",
    "            \n",
    "            # 1. Reflection Step\n",
    "            reflected_point = centroid + self.alpha * (centroid - worst_point)\n",
    "            # Enforce boundary constraints\n",
    "            for i in range(self.dim):\n",
    "                reflected_point[i] = max(self.bounds[i, 0], min(reflected_point[i], self.bounds[i, 1]))\n",
    "            \n",
    "            reflected_objective = self.objective_function(reflected_point)\n",
    "            self.evaluations += 1\n",
    "            self._update_best(reflected_point, reflected_objective)\n",
    "            \n",
    "            if reflected_objective < parent_objectives[-1]:\n",
    "                parents[-1] = reflected_point\n",
    "                parent_objectives[-1] = reflected_objective\n",
    "            else:\n",
    "                # 2. Contraction Step\n",
    "                contracted_point = centroid + self.beta * (worst_point - centroid)\n",
    "                contracted_objective = self.objective_function(contracted_point)\n",
    "                self.evaluations += 1\n",
    "                self._update_best(contracted_point, contracted_objective)\n",
    "                \n",
    "                if contracted_objective < parent_objectives[-1]:\n",
    "                    parents[-1] = contracted_point\n",
    "                    parent_objectives[-1] = contracted_objective\n",
    "                else:\n",
    "                    # 3. Mutation Step\n",
    "                    random_point = np.zeros(self.dim)\n",
    "                    for i in range(self.dim):\n",
    "                        random_point[i] = np.random.uniform(self.bounds[i, 0], self.bounds[i, 1])\n",
    "                    \n",
    "                    random_objective = self.objective_function(random_point)\n",
    "                    self.evaluations += 1\n",
    "                    self._update_best(random_point, random_objective)\n",
    "                    \n",
    "                    parents[-1] = random_point\n",
    "                    parent_objectives[-1] = random_objective\n",
    "            \n",
    "            # Update points in the complex\n",
    "            complex_points[parent_indices] = parents\n",
    "            complex_objectives[parent_indices] = parent_objectives\n",
    "            \n",
    "            # Re-sort the complex\n",
    "            sort_indices = np.argsort(complex_objectives)\n",
    "            complex_points = complex_points[sort_indices]\n",
    "            complex_objectives = complex_objectives[sort_indices]\n",
    "        \n",
    "        return complex_points, complex_objectives\n",
    "\n",
    "    def _update_best(self, point, obj):\n",
    "        \"\"\"Helper to update the global best solution.\"\"\"\n",
    "        if obj < self.best_objective:\n",
    "            self.best_objective = obj\n",
    "            self.best_solution = point.copy()\n",
    "        self.evolution_history.append(self.best_objective)\n",
    "\n",
    "    def optimize(self):\n",
    "        \"\"\"\n",
    "        Execute the main optimization loop.\n",
    "        \n",
    "        Returns:\n",
    "            best_solution (array): The optimal parameter set.\n",
    "            best_objective (float): The best objective function value (Negative NSE).\n",
    "            evolution_history (list): History of the best objective value over evaluations.\n",
    "        \"\"\"\n",
    "        population, objectives = self.generate_initial_population()\n",
    "        \n",
    "        while self.evaluations < self.max_evaluations:\n",
    "            # 1. Partition into complexes\n",
    "            complexes, complex_objectives = self.partition_into_complexes(population, objectives)\n",
    "            \n",
    "            evolved_complexes = []\n",
    "            evolved_objectives = []\n",
    "            \n",
    "            # 2. Evolve each complex independently\n",
    "            for i in range(self.num_complexes):\n",
    "                c_pts, c_objs = self.evolve_complex(complexes[i], complex_objectives[i])\n",
    "                evolved_complexes.append(c_pts)\n",
    "                evolved_objectives.append(c_objs)\n",
    "            \n",
    "            # 3. Recombine (Un-shuffle) the population\n",
    "            population = np.zeros((self.num_points, self.dim))\n",
    "            objectives = np.zeros(self.num_points)\n",
    "            \n",
    "            idx = 0\n",
    "            for i in range(self.num_complexes):\n",
    "                for j in range(len(evolved_complexes[i])):\n",
    "                    if idx < self.num_points:\n",
    "                        population[idx] = evolved_complexes[i][j]\n",
    "                        objectives[idx] = evolved_objectives[i][j]\n",
    "                        idx += 1\n",
    "            \n",
    "            # 4. Sort the new population\n",
    "            sort_indices = np.argsort(objectives)\n",
    "            population = population[sort_indices]\n",
    "            objectives = objectives[sort_indices]\n",
    "            \n",
    "            print(f\"Evaluation {self.evaluations}: Best NSE = {-self.best_objective:.6f}\")\n",
    "            \n",
    "            # Convergence check (stop if standard deviation is very small)\n",
    "            if np.std(objectives) < 1e-6:\n",
    "                print(\"Algorithm converged!\")\n",
    "                break\n",
    "        \n",
    "        return self.best_solution, self.best_objective, self.evolution_history\n",
    "\n",
    "# ==========================================\n",
    "# 3. Helper Functions (File I/O & Utils)\n",
    "# ==========================================\n",
    "\n",
    "def format_fortran_line(par_name, params_dict, num_landuse):\n",
    "    \"\"\"\n",
    "    Format a parameter line string for Fortran input (using 'd0' for double precision).\n",
    "    \n",
    "    Args:\n",
    "        par_name: Parameter name tag (e.g., '# ns_slope').\n",
    "        params_dict: Dictionary containing current parameter values.\n",
    "        num_landuse: Number of land use types (determines values per line).\n",
    "    \"\"\"\n",
    "    values = []\n",
    "    base_name = par_name[2:].strip() # Remove '# '\n",
    "    for j in range(num_landuse):\n",
    "        param_key = f\"{base_name}_{j+1}\"\n",
    "        if param_key in params_dict:\n",
    "            values.append(f\"{params_dict[param_key]:.6f}d0\")\n",
    "        else:\n",
    "            print(f\"Error: Parameter {param_key} not found in dictionary.\")\n",
    "            exit(1)\n",
    "    return '\\t'.join(values) + f\"      # {base_name}\\n\"\n",
    "\n",
    "def modify_rri_input_file(params_dict, rain_file_path, duration_hours):\n",
    "    \"\"\"\n",
    "    Modify the 'RRI_Input.txt' file.\n",
    "    Updates parameter values, rainfall file path, and simulation duration for the Fortran model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(PATHS['rri_input'], 'r') as f:\n",
    "            lines = f.readlines()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {PATHS['rri_input']} not found.\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Construct full rainfall path\n",
    "    full_rain_path = os.path.join(PATHS['rain_folder'], rain_file_path)\n",
    "    \n",
    "    # Update rain path and time settings (Relies on specific line numbers)\n",
    "    lines[2] = f\"{full_rain_path}\\n\"\n",
    "    lines[9] = f\"{duration_hours}    # lasth(hour)\\n\"\n",
    "    lines[12] = f\"{duration_hours}    # outnum [-]\\n\"\n",
    "\n",
    "    # Retrieve number of land use types\n",
    "    num_landuse = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if \"# num_of_landuse\" in line:\n",
    "            num_landuse = int(lines[i].split('#')[0].strip())\n",
    "            break\n",
    "    \n",
    "    if num_landuse is None:\n",
    "        raise ValueError(\"Could not find 'num_of_landuse' in RRI_Input.txt\")\n",
    "    \n",
    "    # Update lines based on parameter dictionary\n",
    "    target_params = [\"# ns_slope\", \"# soildepth\", \"# gammaa\", \"# ksv\", \n",
    "                     \"# faif\", \"# ka\", \"# gammam\", \"# beta\"]\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if \"# ns_river\" in line and 'ns_river' in params_dict:\n",
    "            lines[i] = f\"{params_dict['ns_river']:.6f}d0     # ns_river\\n\"\n",
    "        else:\n",
    "            for tag in target_params:\n",
    "                if tag in line:\n",
    "                    lines[i] = format_fortran_line(tag, params_dict, num_landuse)\n",
    "                    break\n",
    "    \n",
    "    with open(PATHS['rri_input'], 'w') as f:\n",
    "        f.writelines(lines)\n",
    "\n",
    "def get_raster_info(tif_path):\n",
    "    \"\"\"Read GeoTIFF metadata (columns, rows, and geotransform parameters).\"\"\"\n",
    "    ds = gdal.Open(tif_path)\n",
    "    if ds is None:\n",
    "        raise Exception(f\"Cannot open raster file: {tif_path}\")\n",
    "    return {\n",
    "        'cols': ds.RasterXSize,\n",
    "        'rows': ds.RasterYSize,\n",
    "        'geotransform': ds.GetGeoTransform(),\n",
    "        'dataset': ds\n",
    "    }\n",
    "\n",
    "def lonlat_to_xy(lon, lat, geotransform):\n",
    "    \"\"\"\n",
    "    Convert Longitude/Latitude coordinates to raster pixel coordinates (Column/x, Row/y).\n",
    "    \"\"\"\n",
    "    x_origin = geotransform[0]\n",
    "    y_origin = geotransform[3]\n",
    "    pixel_width = geotransform[1]\n",
    "    pixel_height = geotransform[5]\n",
    "    \n",
    "    x = int((lon - x_origin) / pixel_width)\n",
    "    y = int((lat - y_origin) / pixel_height)\n",
    "    return x, y\n",
    "\n",
    "def read_out_file(out_file):\n",
    "    \"\"\"\n",
    "    Read the output matrix from a single RRI .out file.\n",
    "    Typically ASCII Grid format without headers.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.loadtxt(out_file)\n",
    "    except Exception:\n",
    "        # Fallback manual parsing if loadtxt fails\n",
    "        with open(out_file, 'r') as f:\n",
    "            lines = [l.strip() for l in f if l.strip() and not l.strip().startswith('#')]\n",
    "        return np.array([[float(v) for v in l.split()] for l in lines])\n",
    "\n",
    "def extract_time_series(lon, lat, tif_path, out_folder, out_prefix):\n",
    "    \"\"\"\n",
    "    Extract time-series data for a specific coordinate from a sequence of output files.\n",
    "    \n",
    "    Args:\n",
    "        lon, lat: Target coordinates.\n",
    "        tif_path: Reference DEM path for coordinate conversion.\n",
    "        out_folder: Directory containing .out files.\n",
    "        out_prefix: Prefix of output files.\n",
    "    Returns:\n",
    "        Dictionary containing time steps and values, or None if out of bounds.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        raster_info = get_raster_info(tif_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    x, y = lonlat_to_xy(lon, lat, raster_info['geotransform'])\n",
    "    \n",
    "    if not (0 <= x < raster_info['cols'] and 0 <= y < raster_info['rows']):\n",
    "        print(f\"Coordinates ({lon}, {lat}) represent out of DEM bounds.\")\n",
    "        return None\n",
    "    \n",
    "    # Find and sort output files\n",
    "    all_files = os.listdir(out_folder)\n",
    "    # Regex match for qr_1.out, qr_2.out, etc.\n",
    "    pattern = re.compile(rf'{out_prefix}_(\\d+)\\.out')\n",
    "    out_files = sorted(\n",
    "        [os.path.join(out_folder, f) for f in all_files if pattern.match(f)],\n",
    "        key=lambda x: int(pattern.search(os.path.basename(x)).group(1))\n",
    "    )\n",
    "    \n",
    "    if not out_files:\n",
    "        return None\n",
    "    \n",
    "    values = []\n",
    "    steps = []\n",
    "    \n",
    "    for fpath in out_files:\n",
    "        step = int(pattern.search(os.path.basename(fpath)).group(1))\n",
    "        steps.append(step)\n",
    "        data = read_out_file(fpath)\n",
    "        \n",
    "        # Note: numpy uses [row, col], i.e., [y, x]\n",
    "        if y < data.shape[0] and x < data.shape[1]:\n",
    "            values.append(data[y, x])\n",
    "        else:\n",
    "            values.append(np.nan)\n",
    "            \n",
    "    return {'time_steps': steps, 'values': values, 'lon': lon, 'lat': lat, 'x': x, 'y': y}\n",
    "\n",
    "def batch_process_locations(locations, output_folder):\n",
    "    \"\"\"\n",
    "    Batch process all observation locations, save results to CSV, and clean up temporary .out files.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    results = []\n",
    "    for lon, lat in locations:\n",
    "        ts = extract_time_series(lon, lat, PATHS['dem'], PATHS['out_folder'], PATHS['out_prefix'])\n",
    "        if ts:\n",
    "            results.append(ts)\n",
    "    \n",
    "    # Save combined results\n",
    "    dfs = []\n",
    "    for res in results:\n",
    "        dfs.append(pd.DataFrame({\n",
    "            'time_step': res['time_steps'],\n",
    "            'value': res['values'],\n",
    "            'lon': res['lon'],\n",
    "            'lat': res['lat']\n",
    "        }))\n",
    "    \n",
    "    if dfs:\n",
    "        pd.concat(dfs).to_csv(os.path.join(output_folder, 'time_series_data.csv'), index=False)\n",
    "    \n",
    "    # Cleanup temporary output files in the 'out' folder\n",
    "    for f in os.listdir(PATHS['out_folder']):\n",
    "        try:\n",
    "            os.remove(os.path.join(PATHS['out_folder'], f))\n",
    "        except OSError:\n",
    "            pass\n",
    "            \n",
    "    return results\n",
    "\n",
    "def get_simulated_values():\n",
    "    \"\"\"Execute data extraction logic and return simulated values as a 1D array.\"\"\"\n",
    "    batch_process_locations(LOCATIONS, PATHS['result_folder'])\n",
    "    try:\n",
    "        df = pd.read_csv(os.path.join(PATHS['result_folder'], \"time_series_data.csv\"))\n",
    "        return df['value'].values\n",
    "    except Exception:\n",
    "        return np.array([])\n",
    "\n",
    "# ==========================================\n",
    "# 4. Objective Function & Model Execution\n",
    "# ==========================================\n",
    "\n",
    "def run_model_and_evaluate(params, param_names, fixed_params=None):\n",
    "    \"\"\"\n",
    "    Core Objective Function: Runs the RRI model and calculates average NSE.\n",
    "    \n",
    "    Args:\n",
    "        params (list): Current list of parameter values from SCE-UA.\n",
    "        param_names (list): Corresponding parameter names.\n",
    "        fixed_params (dict): Dictionary of fixed parameters.\n",
    "        \n",
    "    Returns:\n",
    "        float: Negative Average NSE (-AvgNSE).\n",
    "        Note: SCE-UA minimizes the function, but higher NSE is better, so we return negative NSE.\n",
    "        Returns infinity if the run fails or data is missing.\n",
    "    \"\"\"\n",
    "    # Merge optimized and fixed parameters\n",
    "    params_dict = dict(zip(param_names, params))\n",
    "    if fixed_params:\n",
    "        params_dict.update(fixed_params)\n",
    "    \n",
    "    nses_sum = 0.0\n",
    "    \n",
    "    # Iterate through all rainfall events\n",
    "    for index, (rain_file, duration) in enumerate(RAIN_EVENTS):\n",
    "        \n",
    "        # 1. Modify input file configuration\n",
    "        modify_rri_input_file(params_dict, rain_file, duration)\n",
    "        \n",
    "        # 2. Run external executable\n",
    "        try:\n",
    "            # Ensure correct working directory for DLLs/Configs\n",
    "            subprocess.run([PATHS['rri_exe']], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Run Error in event {index}: {e}\")\n",
    "            return float('inf') # Return infinity indicating invalid parameters\n",
    "        \n",
    "        # 3. Retrieve simulated results\n",
    "        sim_data = get_simulated_values()\n",
    "        \n",
    "        # 4. Get observation data (from Excel)\n",
    "        try:\n",
    "            obs_df = pd.read_excel(PATHS['obs_data'])\n",
    "            # Assuming Excel columns are 1, 2, 3... corresponding to event index + 1\n",
    "            obs_values = obs_df[index + 1].values\n",
    "            obs_values = obs_values[~np.isnan(obs_values)] # Remove NaNs\n",
    "        except Exception as e:\n",
    "            print(f\"Obs Data Error: {e}\")\n",
    "            return float('inf')\n",
    "        \n",
    "        # 5. Calculate NSE for the single event\n",
    "        if len(sim_data) != len(obs_values) or len(obs_values) == 0:\n",
    "            print(f\"Data length mismatch: Sim {len(sim_data)} vs Obs {len(obs_values)}\")\n",
    "            return float('inf')\n",
    "            \n",
    "        mean_obs = np.mean(obs_values)\n",
    "        denominator = np.sum((obs_values - mean_obs) ** 2)\n",
    "        \n",
    "        if denominator == 0:\n",
    "            nse = -1e9 # Avoid division by zero, assign a very low value\n",
    "        else:\n",
    "            nse = 1 - np.sum((obs_values - sim_data) ** 2) / denominator\n",
    "            \n",
    "        print(f\"  Event {index+1} NSE: {nse:.4f}\")\n",
    "        nses_sum += nse\n",
    "\n",
    "    avg_nse = nses_sum / len(RAIN_EVENTS)\n",
    "    print(f\"Avg NSE: {avg_nse:.4f}\")\n",
    "    \n",
    "    # Return negative value for minimization\n",
    "    return -avg_nse\n",
    "\n",
    "# ==========================================\n",
    "# 5. Main Entry Point\n",
    "# ==========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Prepare list of parameter names and boundaries\n",
    "    param_names = list(PARAMS_BOUNDS.keys())\n",
    "    # Remove fixed parameters from bounds just in case\n",
    "    for p in FIXED_PARAMS:\n",
    "        if p in PARAMS_BOUNDS:\n",
    "            del PARAMS_BOUNDS[p]\n",
    "            \n",
    "    bounds = [PARAMS_BOUNDS[name] for name in param_names]\n",
    "\n",
    "    # Define objective function wrapper (lambda), fixing inputs other than 'p'\n",
    "    objective_func = lambda p: run_model_and_evaluate(p, param_names, FIXED_PARAMS)\n",
    "\n",
    "    # Initialize SCE-UA Optimizer\n",
    "    optimizer = SCEUA(\n",
    "        objective_function=objective_func,\n",
    "        bounds=bounds,\n",
    "        max_evaluations=10000,     # Max number of evaluations\n",
    "        num_complexes=5,          # Number of complexes\n",
    "        points_per_complex=21,    # Points per complex\n",
    "        num_points=105,           # Total points (usually complexes * points_per_complex)\n",
    "        num_evolution_steps=21    # Internal evolution steps\n",
    "    )\n",
    "\n",
    "    print(\"Starting SCE-UA Optimization...\")\n",
    "    print(f\"Optimizing {len(param_names)} parameters.\")\n",
    "    \n",
    "    # Start optimization process\n",
    "    best_params, best_obj, history = optimizer.optimize()\n",
    "\n",
    "    # Output results\n",
    "    print(\"\\nOptimization Finished!\")\n",
    "    # Note: best_obj is negative NSE, negate it to show the real NSE\n",
    "    print(f\"Best Avg NSE: {-best_obj:.6f}\")\n",
    "    print(\"Best Parameters:\")\n",
    "    \n",
    "    results_dict = FIXED_PARAMS.copy()\n",
    "    for i, name in enumerate(param_names):\n",
    "        print(f\"{name}: {best_params[i]:.6f}\")\n",
    "        results_dict[name] = best_params[i]\n",
    "\n",
    "    # Save optimal parameters to file\n",
    "    with open('optimal_parameters.txt', 'w') as f:\n",
    "        f.write(\"Optimal Parameters:\\n\")\n",
    "        for name, value in results_dict.items():\n",
    "            f.write(f\"{name}: {value}\\n\")\n",
    "        f.write(f\"\\nBest NSE: {-best_obj}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leafmap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
